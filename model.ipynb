{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fc5ac1e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package gutenberg to C:\\Users\\Rahul\n",
      "[nltk_data]     patel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package gutenberg is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "## Data Loading\n",
    "import nltk\n",
    "nltk.download('gutenberg')\n",
    "from nltk.corpus import gutenberg\n",
    "import pandas as pd\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc1a23b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Function to load subset of dataset to  disk (~5GB)\n",
    "def save_subset(dataset, max_size_mb=5000, output_file='openwebtext_subset.txt'):\n",
    "    \"\"\"\n",
    "    Save a subset of the dataset to disk, limiting to max_size_mb (in MB).\n",
    "    \"\"\"\n",
    "    max_size_bytes = max_size_mb * 1024 * 1024  # Convert MB to bytes\n",
    "    current_size = 0\n",
    "    \n",
    "    with open(output_file, 'w', encoding='utf-8') as f:\n",
    "        for item in dataset:\n",
    "            text = item['text']\n",
    "            text_size = len(text.encode('utf-8'))\n",
    "            if current_size + text_size > max_size_bytes:\n",
    "                break\n",
    "            f.write(text + '\\n')\n",
    "            current_size += text_size\n",
    "    \n",
    "    print(f\"Saved subset to {output_file}, size: {current_size / (1024 * 1024):.2f} MB\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa51a5cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Dataset...\n",
      "Dataset Loaded\n"
     ]
    }
   ],
   "source": [
    "## Load Dataset\n",
    "print(\"Loading Dataset...\")\n",
    "data = gutenberg.raw('austen-emma.txt')\n",
    "print(\"Dataset Loaded\")\n",
    "\n",
    "# Save File\n",
    "with open('emma.txt', 'w', encoding='utf-8') as file:\n",
    "    file.write(data)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f25b169",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing text...\n",
      "Total words: 7233\n"
     ]
    }
   ],
   "source": [
    "## Data Preprocessing\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "\n",
    "# Load the dataset\n",
    "with open('emma.txt', 'r',encoding='utf-8') as file:\n",
    "    text = file.read().lower()\n",
    "\n",
    "## Tokenize the text ( convert words to integers)\n",
    "print(\"Tokenizing text...\")\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts([text])\n",
    "total_words = len(tokenizer.word_index) + 1  # +1 for padding token\n",
    "print(f\"Total words: {total_words}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e4ec8bc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating input sequences...\n",
      "Total input sequences generated: 146818\n"
     ]
    }
   ],
   "source": [
    "## Input Sequences\n",
    "print(\"Generating input sequences...\")\n",
    "input_sequences = []\n",
    "for line in text.split('\\n'):\n",
    "    token_list = tokenizer.texts_to_sequences([line])[0]\n",
    "    for i in range(1, len(token_list)):\n",
    "        n_gram_sequence = token_list[:i + 1]\n",
    "        input_sequences.append(n_gram_sequence)\n",
    "print(\"Total input sequences generated:\", len(input_sequences))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de06586",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input sequences shape: (146818, 17)\n"
     ]
    }
   ],
   "source": [
    "## Pad Sequences\n",
    "max_sequence_length = max([len(x) for x in input_sequences])\n",
    "input_sequences = pad_sequences(input_sequences, maxlen=max_sequence_length, padding='pre')\n",
    "print(f\"Input sequences shape: {input_sequences.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a465440b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,    0,    0, ...,    0,   32,   45],\n",
       "       [   0,    0,    0, ...,   32,   45,   92],\n",
       "       [   0,    0,    0, ...,   45,   92, 4410],\n",
       "       ...,\n",
       "       [   0,    0,    0, ...,  534,  260,    4],\n",
       "       [   0,    0,    0, ...,  260,    4,    2],\n",
       "       [   0,    0,    0, ...,    4,    2, 2784]], dtype=int32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f128666d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating predictors and labels...\n",
      "Created predictors and labels\n"
     ]
    }
   ],
   "source": [
    "## Create predictors and label\n",
    "print(\"Creating predictors and labels...\")\n",
    "x, y = input_sequences[:, :-1], input_sequences[:, -1]\n",
    "y = tf.keras.utils.to_categorical(y, num_classes=total_words)\n",
    "print(\"Created predictors and labels\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "53336172",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting data into training and testing sets...\n"
     ]
    }
   ],
   "source": [
    "## Split the data into training and testing sets\n",
    "print(\"Splitting data into training and testing sets...\")\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e255fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)        │       <span style=\"color: #00af00; text-decoration-color: #00af00\">723,300</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)        │       <span style=\"color: #00af00; text-decoration-color: #00af00\">240,800</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">120,400</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7233</span>)           │       <span style=\"color: #00af00; text-decoration-color: #00af00\">730,533</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m100\u001b[0m)        │       \u001b[38;5;34m723,300\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_2 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m200\u001b[0m)        │       \u001b[38;5;34m240,800\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m200\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_3 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │       \u001b[38;5;34m120,400\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7233\u001b[0m)           │       \u001b[38;5;34m730,533\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,815,033</span> (6.92 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,815,033\u001b[0m (6.92 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,815,033</span> (6.92 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,815,033\u001b[0m (6.92 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Compiled\n"
     ]
    }
   ],
   "source": [
    "## Training the Model (LSTM RNN)\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "\n",
    "## Define the model\n",
    "model = Sequential()\n",
    "model.add(Embedding(total_words, 100, input_length=max_sequence_length-1))  # Define input_length\n",
    "model.add(LSTM(200, return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(100))\n",
    "model.add(Dense(total_words, activation='softmax'))\n",
    "model.build(input_shape=(None, max_sequence_length-1))  # Define input_shape for the model\n",
    "\n",
    "## Compiling the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()\n",
    "print(\"Model Compiled\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0c2a9c82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the model...\n",
      "Epoch 1/60\n",
      "\u001b[1m3671/3671\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 34ms/step - accuracy: 0.0390 - loss: 6.4944 - val_accuracy: 0.0924 - val_loss: 5.8378\n",
      "Epoch 2/60\n",
      "\u001b[1m3671/3671\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m130s\u001b[0m 35ms/step - accuracy: 0.1016 - loss: 5.6070 - val_accuracy: 0.1127 - val_loss: 5.6265\n",
      "Epoch 3/60\n",
      "\u001b[1m3671/3671\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 35ms/step - accuracy: 0.1179 - loss: 5.2918 - val_accuracy: 0.1233 - val_loss: 5.5615\n",
      "Epoch 4/60\n",
      "\u001b[1m3671/3671\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 33ms/step - accuracy: 0.1296 - loss: 5.0723 - val_accuracy: 0.1279 - val_loss: 5.5697\n",
      "Epoch 5/60\n",
      "\u001b[1m3671/3671\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 31ms/step - accuracy: 0.1385 - loss: 4.9218 - val_accuracy: 0.1333 - val_loss: 5.6033\n",
      "Epoch 6/60\n",
      "\u001b[1m3671/3671\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 31ms/step - accuracy: 0.1440 - loss: 4.7960 - val_accuracy: 0.1373 - val_loss: 5.6498\n",
      "Epoch 7/60\n",
      "\u001b[1m3671/3671\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 31ms/step - accuracy: 0.1489 - loss: 4.6887 - val_accuracy: 0.1373 - val_loss: 5.7193\n",
      "Epoch 8/60\n",
      "\u001b[1m3671/3671\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 32ms/step - accuracy: 0.1503 - loss: 4.5945 - val_accuracy: 0.1400 - val_loss: 5.7833\n",
      "Epoch 9/60\n",
      "\u001b[1m3671/3671\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 32ms/step - accuracy: 0.1569 - loss: 4.5002 - val_accuracy: 0.1409 - val_loss: 5.8494\n",
      "Epoch 10/60\n",
      "\u001b[1m3671/3671\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 32ms/step - accuracy: 0.1600 - loss: 4.4293 - val_accuracy: 0.1443 - val_loss: 5.9191\n",
      "Epoch 11/60\n",
      "\u001b[1m3671/3671\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 32ms/step - accuracy: 0.1631 - loss: 4.3555 - val_accuracy: 0.1425 - val_loss: 5.9931\n",
      "Epoch 12/60\n",
      "\u001b[1m3671/3671\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 32ms/step - accuracy: 0.1674 - loss: 4.2932 - val_accuracy: 0.1450 - val_loss: 6.0741\n",
      "Epoch 13/60\n",
      "\u001b[1m3671/3671\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 32ms/step - accuracy: 0.1716 - loss: 4.2231 - val_accuracy: 0.1452 - val_loss: 6.1389\n",
      "Epoch 14/60\n",
      "\u001b[1m3671/3671\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 32ms/step - accuracy: 0.1778 - loss: 4.1665 - val_accuracy: 0.1428 - val_loss: 6.2182\n",
      "Epoch 15/60\n",
      "\u001b[1m3671/3671\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 32ms/step - accuracy: 0.1791 - loss: 4.1177 - val_accuracy: 0.1443 - val_loss: 6.2807\n",
      "Epoch 16/60\n",
      "\u001b[1m3671/3671\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 31ms/step - accuracy: 0.1836 - loss: 4.0678 - val_accuracy: 0.1445 - val_loss: 6.3437\n",
      "Epoch 17/60\n",
      "\u001b[1m3671/3671\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 32ms/step - accuracy: 0.1874 - loss: 4.0191 - val_accuracy: 0.1432 - val_loss: 6.4285\n",
      "Epoch 18/60\n",
      "\u001b[1m3671/3671\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 32ms/step - accuracy: 0.1912 - loss: 3.9747 - val_accuracy: 0.1440 - val_loss: 6.5221\n",
      "Epoch 19/60\n",
      "\u001b[1m3671/3671\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 31ms/step - accuracy: 0.1961 - loss: 3.9183 - val_accuracy: 0.1404 - val_loss: 6.5712\n",
      "Epoch 20/60\n",
      "\u001b[1m3671/3671\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 32ms/step - accuracy: 0.2000 - loss: 3.8801 - val_accuracy: 0.1417 - val_loss: 6.6485\n",
      "Epoch 21/60\n",
      "\u001b[1m3671/3671\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 32ms/step - accuracy: 0.2038 - loss: 3.8429 - val_accuracy: 0.1427 - val_loss: 6.7169\n",
      "Epoch 22/60\n",
      "\u001b[1m3671/3671\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 34ms/step - accuracy: 0.2090 - loss: 3.8057 - val_accuracy: 0.1401 - val_loss: 6.7679\n",
      "Epoch 23/60\n",
      "\u001b[1m3671/3671\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 32ms/step - accuracy: 0.2155 - loss: 3.7635 - val_accuracy: 0.1396 - val_loss: 6.8557\n",
      "Epoch 24/60\n",
      "\u001b[1m3671/3671\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 32ms/step - accuracy: 0.2174 - loss: 3.7317 - val_accuracy: 0.1406 - val_loss: 6.9126\n",
      "Epoch 25/60\n",
      "\u001b[1m3671/3671\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 34ms/step - accuracy: 0.2238 - loss: 3.6918 - val_accuracy: 0.1395 - val_loss: 6.9614\n",
      "Epoch 26/60\n",
      "\u001b[1m3671/3671\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 32ms/step - accuracy: 0.2259 - loss: 3.6560 - val_accuracy: 0.1383 - val_loss: 7.0142\n",
      "Epoch 27/60\n",
      "\u001b[1m3671/3671\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 32ms/step - accuracy: 0.2316 - loss: 3.6256 - val_accuracy: 0.1370 - val_loss: 7.0989\n",
      "Epoch 28/60\n",
      "\u001b[1m3671/3671\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 33ms/step - accuracy: 0.2336 - loss: 3.5965 - val_accuracy: 0.1370 - val_loss: 7.1446\n",
      "Epoch 29/60\n",
      "\u001b[1m3671/3671\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 33ms/step - accuracy: 0.2423 - loss: 3.5574 - val_accuracy: 0.1371 - val_loss: 7.1994\n",
      "Epoch 30/60\n",
      "\u001b[1m3671/3671\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 33ms/step - accuracy: 0.2443 - loss: 3.5322 - val_accuracy: 0.1354 - val_loss: 7.2805\n",
      "Epoch 31/60\n",
      "\u001b[1m3671/3671\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 33ms/step - accuracy: 0.2472 - loss: 3.5057 - val_accuracy: 0.1343 - val_loss: 7.3275\n",
      "Epoch 32/60\n",
      "\u001b[1m3671/3671\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 34ms/step - accuracy: 0.2524 - loss: 3.4765 - val_accuracy: 0.1336 - val_loss: 7.3679\n",
      "Epoch 33/60\n",
      "\u001b[1m3671/3671\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 33ms/step - accuracy: 0.2570 - loss: 3.4452 - val_accuracy: 0.1348 - val_loss: 7.4230\n",
      "Epoch 34/60\n",
      "\u001b[1m3671/3671\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 33ms/step - accuracy: 0.2609 - loss: 3.4171 - val_accuracy: 0.1328 - val_loss: 7.4683\n",
      "Epoch 35/60\n",
      "\u001b[1m3671/3671\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 32ms/step - accuracy: 0.2607 - loss: 3.3991 - val_accuracy: 0.1327 - val_loss: 7.5399\n",
      "Epoch 36/60\n",
      "\u001b[1m3671/3671\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 34ms/step - accuracy: 0.2655 - loss: 3.3717 - val_accuracy: 0.1313 - val_loss: 7.6130\n",
      "Epoch 37/60\n",
      "\u001b[1m3671/3671\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 33ms/step - accuracy: 0.2700 - loss: 3.3522 - val_accuracy: 0.1305 - val_loss: 7.6289\n",
      "Epoch 38/60\n",
      "\u001b[1m3671/3671\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 33ms/step - accuracy: 0.2760 - loss: 3.3225 - val_accuracy: 0.1279 - val_loss: 7.6873\n",
      "Epoch 39/60\n",
      "\u001b[1m3671/3671\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 34ms/step - accuracy: 0.2776 - loss: 3.2939 - val_accuracy: 0.1310 - val_loss: 7.7379\n",
      "Epoch 40/60\n",
      "\u001b[1m3671/3671\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 33ms/step - accuracy: 0.2837 - loss: 3.2670 - val_accuracy: 0.1288 - val_loss: 7.7848\n",
      "Epoch 41/60\n",
      "\u001b[1m3671/3671\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 33ms/step - accuracy: 0.2849 - loss: 3.2566 - val_accuracy: 0.1289 - val_loss: 7.8374\n",
      "Epoch 42/60\n",
      "\u001b[1m3671/3671\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 33ms/step - accuracy: 0.2877 - loss: 3.2161 - val_accuracy: 0.1300 - val_loss: 7.8909\n",
      "Epoch 43/60\n",
      "\u001b[1m3671/3671\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 35ms/step - accuracy: 0.2940 - loss: 3.2057 - val_accuracy: 0.1284 - val_loss: 7.9193\n",
      "Epoch 44/60\n",
      "\u001b[1m3671/3671\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 34ms/step - accuracy: 0.2946 - loss: 3.1973 - val_accuracy: 0.1276 - val_loss: 7.9929\n",
      "Epoch 45/60\n",
      "\u001b[1m3671/3671\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 34ms/step - accuracy: 0.3007 - loss: 3.1563 - val_accuracy: 0.1248 - val_loss: 8.0357\n",
      "Epoch 46/60\n",
      "\u001b[1m3671/3671\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 34ms/step - accuracy: 0.3024 - loss: 3.1444 - val_accuracy: 0.1244 - val_loss: 8.0675\n",
      "Epoch 47/60\n",
      "\u001b[1m3671/3671\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 35ms/step - accuracy: 0.3020 - loss: 3.1346 - val_accuracy: 0.1260 - val_loss: 8.1009\n",
      "Epoch 48/60\n",
      "\u001b[1m3671/3671\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 34ms/step - accuracy: 0.3056 - loss: 3.1161 - val_accuracy: 0.1265 - val_loss: 8.1574\n",
      "Epoch 49/60\n",
      "\u001b[1m3671/3671\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 34ms/step - accuracy: 0.3120 - loss: 3.0990 - val_accuracy: 0.1255 - val_loss: 8.2078\n",
      "Epoch 50/60\n",
      "\u001b[1m3671/3671\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 33ms/step - accuracy: 0.3127 - loss: 3.0800 - val_accuracy: 0.1246 - val_loss: 8.2813\n",
      "Epoch 51/60\n",
      "\u001b[1m3671/3671\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 34ms/step - accuracy: 0.3146 - loss: 3.0581 - val_accuracy: 0.1248 - val_loss: 8.2883\n",
      "Epoch 52/60\n",
      "\u001b[1m3671/3671\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 34ms/step - accuracy: 0.3186 - loss: 3.0472 - val_accuracy: 0.1242 - val_loss: 8.3375\n",
      "Epoch 53/60\n",
      "\u001b[1m3671/3671\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 34ms/step - accuracy: 0.3207 - loss: 3.0339 - val_accuracy: 0.1246 - val_loss: 8.3416\n",
      "Epoch 54/60\n",
      "\u001b[1m3671/3671\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 34ms/step - accuracy: 0.3235 - loss: 3.0117 - val_accuracy: 0.1234 - val_loss: 8.4097\n",
      "Epoch 55/60\n",
      "\u001b[1m3671/3671\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 34ms/step - accuracy: 0.3277 - loss: 2.9882 - val_accuracy: 0.1217 - val_loss: 8.4636\n",
      "Epoch 56/60\n",
      "\u001b[1m3671/3671\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 34ms/step - accuracy: 0.3290 - loss: 2.9814 - val_accuracy: 0.1233 - val_loss: 8.5111\n",
      "Epoch 57/60\n",
      "\u001b[1m3671/3671\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 34ms/step - accuracy: 0.3305 - loss: 2.9704 - val_accuracy: 0.1200 - val_loss: 8.5319\n",
      "Epoch 58/60\n",
      "\u001b[1m3671/3671\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 35ms/step - accuracy: 0.3305 - loss: 2.9704 - val_accuracy: 0.1199 - val_loss: 8.5986\n",
      "Epoch 59/60\n",
      "\u001b[1m3671/3671\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 34ms/step - accuracy: 0.3384 - loss: 2.9398 - val_accuracy: 0.1223 - val_loss: 8.6466\n",
      "Epoch 60/60\n",
      "\u001b[1m3671/3671\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 35ms/step - accuracy: 0.3378 - loss: 2.9249 - val_accuracy: 0.1209 - val_loss: 8.6614\n",
      "Model Training Completed\n"
     ]
    }
   ],
   "source": [
    "## Training the model\n",
    "print(\"Training the model...\")\n",
    "history = model.fit(x_train, y_train, epochs=60, validation_data=(x_test, y_test), verbose=1)\n",
    "print(\"Model Training Completed\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a8368954",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "## Saving the model\n",
    "model.save('Next_Word_Predictor_LSTM.h5')\n",
    "\n",
    "## Save the tokenizer\n",
    "with open('tokenizer.pickle', 'wb') as handle:\n",
    "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3ce87633",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Function to predict the next word\n",
    "def predict_next_word(model, tokenizer, text, max_sequence_length):\n",
    "    token_list = tokenizer.texts_to_sequences([text])[0]\n",
    "    if len(token_list) >= max_sequence_length:\n",
    "        token_list = token_list[-(max_sequence_length-1):] # Ensure the sequence length matches max_sequence_length-1\n",
    "    token_list = pad_sequences([token_list], maxlen=max_sequence_length-1, padding='pre')\n",
    "    \n",
    "    # Predict the next word\n",
    "    predicted = model.predict(token_list, verbose=0)\n",
    "    predicted_word_index = np.argmax(predicted, axis=1)\n",
    "    \n",
    "    for word, index in tokenizer.word_index.items():\n",
    "        if index == predicted_word_index:\n",
    "            return word\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f45b33b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input text:  The evil of the actual disparity in their\n",
      "Predicted next word:  ages\n"
     ]
    }
   ],
   "source": [
    "## Testing the model\n",
    "input_text = \"The evil of the actual disparity in their\"\n",
    "print(\"Input text: \", input_text)\n",
    "max_sequence_length = model.input_shape[1] + 1  # +1 for padding token\n",
    "predicted_word = predict_next_word(model, tokenizer, input_text, max_sequence_length)\n",
    "print(\"Predicted next word: \", predicted_word)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
